services:
  transnetv2:
    image: xwzliang/transnetv2_pytorch:0.0.1
    # user: "broliang"
    container_name: transnetv2
    networks:
      - mynet
    restart: always
    build: .
    # For Nvidia GPU's - You probably want to uncomment this
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    devices:
      - "/dev/dri:/dev/dri"
    # environment:
    #   - LD_LIBRARY_PATH=/opt/conda/lib/python3.11/site-packages/nvidia/cudnn/lib:${LD_LIBRARY_PATH}
    volumes:
      - ./inference-pytorch:/tmp/inference-pytorch:delegated
      - ~/videos:/data
      - /mnt/omv:/Volumes/omv
      - ~/models/.cache/huggingface:/root/.cache/huggingface:rshared
    ports:
      - "8007:8000"
    command: uvicorn server:app --app-dir /tmp/inference-pytorch --host 0.0.0.0 --port 8000
networks:
  mynet:
    external: true